"use strict";(self.webpackChunk_revideo_docs=self.webpackChunk_revideo_docs||[]).push([[6331],{2247:(e,r,n)=>{n.d(r,{xA:()=>d,yg:()=>f});var t=n(4041);function o(e,r,n){return r in e?Object.defineProperty(e,r,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[r]=n,e}function i(e,r){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);r&&(t=t.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),n.push.apply(n,t)}return n}function a(e){for(var r=1;r<arguments.length;r++){var n=null!=arguments[r]?arguments[r]:{};r%2?i(Object(n),!0).forEach((function(r){o(e,r,n[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(n,r))}))}return e}function l(e,r){if(null==e)return{};var n,t,o=function(e,r){if(null==e)return{};var n,t,o={},i=Object.keys(e);for(t=0;t<i.length;t++)n=i[t],r.indexOf(n)>=0||(o[n]=e[n]);return o}(e,r);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(t=0;t<i.length;t++)n=i[t],r.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var p=t.createContext({}),s=function(e){var r=t.useContext(p),n=r;return e&&(n="function"==typeof e?e(r):a(a({},r),e)),n},d=function(e){var r=s(e.components);return t.createElement(p.Provider,{value:r},e.children)},g="mdxType",u={inlineCode:"code",wrapper:function(e){var r=e.children;return t.createElement(t.Fragment,{},r)}},m=t.forwardRef((function(e,r){var n=e.components,o=e.mdxType,i=e.originalType,p=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),g=s(n),m=o,f=g["".concat(p,".").concat(m)]||g[m]||u[m]||i;return n?t.createElement(f,a(a({ref:r},d),{},{components:n})):t.createElement(f,a({ref:r},d))}));function f(e,r){var n=arguments,o=r&&r.mdxType;if("string"==typeof e||o){var i=n.length,a=new Array(i);a[0]=m;var l={};for(var p in r)hasOwnProperty.call(r,p)&&(l[p]=r[p]);l.originalType=e,l[g]="string"==typeof e?e:o,a[1]=l;for(var s=2;s<i;s++)a[s]=n[s];return t.createElement.apply(null,a)}return t.createElement.apply(null,n)}m.displayName="MDXCreateElement"},812:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>p,contentTitle:()=>a,default:()=>u,frontMatter:()=>i,metadata:()=>l,toc:()=>s});var t=n(9575),o=(n(4041),n(2247));const i={sidebar_position:2,slug:"/renderer/renderPartialVideo"},a="renderPartialVideo()",l={unversionedId:"api-reference/renderer/renderPartialVideo",id:"api-reference/renderer/renderPartialVideo",title:"renderPartialVideo()",description:"The renderPartialVideo() function lets you render partial videos if you want",source:"@site/docs/api-reference/renderer/renderPartialVideo.mdx",sourceDirName:"api-reference/renderer",slug:"/renderer/renderPartialVideo",permalink:"/renderer/renderPartialVideo",draft:!1,editUrl:"https://github.com/havenhq/revideo/blob/main/packages/docs/docs/api-reference/renderer/renderPartialVideo.mdx",tags:[],version:"current",lastUpdatedBy:"Justus Mattern",sidebarPosition:2,frontMatter:{sidebar_position:2,slug:"/renderer/renderPartialVideo"},sidebar:"docs",previous:{title:"renderVideo()",permalink:"/api/renderer/renderVideo"},next:{title:"@revideo/ffmpeg",permalink:"/category/revideoffmpeg"}},p={},s=[{value:"Example Usage",id:"example-usage",level:2},{value:"Arguments",id:"arguments",level:2},{value:"projectFile:",id:"projectfile",level:3},{value:"workerId",id:"workerid",level:3},{value:"numWorkers",id:"numworkers",level:3},{value:"variables?",id:"variables",level:3},{value:"settings?",id:"settings",level:3},{value:"dimensions?",id:"dimensions",level:4},{value:"logProgress?",id:"logprogress",level:4},{value:"ffmpeg?",id:"ffmpeg",level:4},{value:"ffmpegLogLevel?",id:"ffmpegloglevel",level:5},{value:"ffmpegPath?",id:"ffmpegpath",level:5},{value:"puppeteer?",id:"puppeteer",level:4},{value:"viteBasePort?",id:"vitebaseport",level:4},{value:"viteServerOptions?",id:"viteserveroptions",level:4},{value:"progressCallback?",id:"progresscallback",level:4},{value:"Return Value",id:"return-value",level:2}],d={toc:s},g="wrapper";function u(e){let{components:r,...n}=e;return(0,o.yg)(g,(0,t.A)({},d,n,{components:r,mdxType:"MDXLayout"}),(0,o.yg)("h1",{id:"renderpartialvideo"},"renderPartialVideo()"),(0,o.yg)("p",null,"The ",(0,o.yg)("inlineCode",{parentName:"p"},"renderPartialVideo()")," function lets you render partial videos if you want\nto distribute the rendering workload across multiple workers. You can find an\nexample of this in our\n",(0,o.yg)("a",{parentName:"p",href:"https://github.com/redotvideo/examples/tree/main/google-cloud-run-parallelized"},"Cloud Functions example"),".\nTo use ",(0,o.yg)("inlineCode",{parentName:"p"},"renderPartialVideo()"),", you don't have to manually assign a range of\nframes or timestamps to render. Instead, you just pass the worker id and the\ntotal number of workers your rendering job uses, and the function will figure\nout the frames to render by itself."),(0,o.yg)("p",null,"Since merging partial videos gives you audio issues (audio becomes laggy), this\nfunction returns the path to the audio file and mute video file of the partial\nvideo. Afterwards, you should first concatenate all of the partial audio files\nand then concatenate all of the partial mute video files, and then merge the\nfull audio and video to obtain your final mp4 file."),(0,o.yg)("p",null,"To do this, you can use the ",(0,o.yg)("inlineCode",{parentName:"p"},"concatenateMedia()"),"\n(",(0,o.yg)("a",{parentName:"p",href:"/ffmpeg/concatenateMedia"},"docs"),") and ",(0,o.yg)("inlineCode",{parentName:"p"},"mergeAudioWithVideo()"),"\n(",(0,o.yg)("a",{parentName:"p",href:"/ffmpeg/mergeAudioWithVideo"},"docs"),") functions from ",(0,o.yg)("inlineCode",{parentName:"p"},"@revideo/ffmpeg"),"."),(0,o.yg)("h2",{id:"example-usage"},"Example Usage"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-tsx"},"import {renderPartialVideo} from '@revideo/renderer';\n\nconst {audioFile, videoFile} = renderPartialVideo({\n  projectFile: './src/project.ts',\n  variables: {color: 'white'},\n  numWorkers: 10,\n  workerId: 3,\n  settings: {\n    dimensions: [1080, 1792],\n    logProgress: true,\n    fmpeg: {\n      ffmpegLogLevel: 'error',\n      ffmpegPath: 'ffmpeg',\n    },\n    puppeteer: {\n      args: ['--no-sandbox'],\n    },\n  },\n});\n")),(0,o.yg)("h2",{id:"arguments"},"Arguments"),(0,o.yg)("p",null,"An object of type ",(0,o.yg)("inlineCode",{parentName:"p"},"RenderPartialVideoProps")," with the following attributes:"),(0,o.yg)("h3",{id:"projectfile"},"projectFile:"),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"string")),(0,o.yg)("p",null,"A string pointing towards your Vite config file. This will probably be\n",(0,o.yg)("inlineCode",{parentName:"p"},"./src/project.ts"),"."),(0,o.yg)("h3",{id:"workerid"},"workerId"),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"number")),(0,o.yg)("p",null,"The id of the worker. We start counting at 0, so if you have 5 workers, values\nfrom 0 to 4 are accepted."),(0,o.yg)("h3",{id:"numworkers"},"numWorkers"),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"number")),(0,o.yg)("p",null,"The number of workers you use in total. This informs the function which range of\nthe video to render. For instance, worker 0 out of 10 workers would render 1/10\nof the full video, whereas worker 0 out of 2 would render half of the video."),(0,o.yg)("h3",{id:"variables"},"variables?"),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"Record<string, any>")),(0,o.yg)("p",null,"Parameters / or variables passed to your video. See ",(0,o.yg)("a",{parentName:"p",href:"/parameterized-video"},"here"),"\nlearn more about parameterized videos."),(0,o.yg)("h3",{id:"settings"},"settings?"),(0,o.yg)("p",null,"A ",(0,o.yg)("inlineCode",{parentName:"p"},"Omit<RenderSettings, 'workers' | 'outFile' | 'outDir' | 'range'>")," object with\nthe following properties:"),(0,o.yg)("h4",{id:"dimensions"},"dimensions?"),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"[number, number]")),(0,o.yg)("p",null,"Dimensions of the video to render as ","[x,y]",". Uses the value specified in\n",(0,o.yg)("inlineCode",{parentName:"p"},"project.meta")," by default."),(0,o.yg)("h4",{id:"logprogress"},"logProgress?"),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"boolean")),(0,o.yg)("p",null,"Logs render progress to the console if set to ",(0,o.yg)("inlineCode",{parentName:"p"},"true"),"."),(0,o.yg)("h4",{id:"ffmpeg"},"ffmpeg?"),(0,o.yg)("p",null,"FFmpeg options - is an instance of ",(0,o.yg)("inlineCode",{parentName:"p"},"FfmpegSettings"),". These overwrite the\nfollowing settings set through environment variables:"),(0,o.yg)("h5",{id:"ffmpegloglevel"},"ffmpegLogLevel?"),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},(0,o.yg)("inlineCode",{parentName:"em"},"error")," | ",(0,o.yg)("inlineCode",{parentName:"em"},"warning")," | ",(0,o.yg)("inlineCode",{parentName:"em"},"info")," | ",(0,o.yg)("inlineCode",{parentName:"em"},"verbose"),", ",(0,o.yg)("inlineCode",{parentName:"em"},"debug")," | ",(0,o.yg)("inlineCode",{parentName:"em"},"trace"))),(0,o.yg)("p",null,"The log level of FFmpeg. Can be one of ",(0,o.yg)("inlineCode",{parentName:"p"},"error"),", ",(0,o.yg)("inlineCode",{parentName:"p"},"warning"),", ",(0,o.yg)("inlineCode",{parentName:"p"},"info"),", ",(0,o.yg)("inlineCode",{parentName:"p"},"verbose"),",\n",(0,o.yg)("inlineCode",{parentName:"p"},"debug"),", ",(0,o.yg)("inlineCode",{parentName:"p"},"trace"),". Default is ",(0,o.yg)("inlineCode",{parentName:"p"},"error"),"."),(0,o.yg)("h5",{id:"ffmpegpath"},"ffmpegPath?"),(0,o.yg)("p",null,"The path to the FFmpeg binary. If not specified, the FFmpeg binary shipped with\nRevideo will be used."),(0,o.yg)("h4",{id:"puppeteer"},"puppeteer?"),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"BrowserLaunchArgumentOptions")),(0,o.yg)("p",null,"Launch options for puppeteer - is an instance of puppeteer's\n",(0,o.yg)("a",{parentName:"p",href:"https://pptr.dev/api/puppeteer.browserlaunchargumentoptions/"},"BrowserLaunchArgumentOptions")),(0,o.yg)("h4",{id:"vitebaseport"},"viteBasePort?"),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"number")),(0,o.yg)("p",null,'The "base port" we use for the vite server. When you have three workers and a\nbase port 5000, the vite servers created by the three workers will use port\n5000, 5001, and 5002. Default is 9000.'),(0,o.yg)("h4",{id:"viteserveroptions"},"viteServerOptions?"),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"ServerOptions")),(0,o.yg)("p",null,"Options for the vite server used for rendering. Is an instance of vite's\n",(0,o.yg)("a",{parentName:"p",href:"https://vitejs.dev/config/server-options"},"ServerOptions"),"."),(0,o.yg)("h4",{id:"progresscallback"},"progressCallback?"),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"(worker: number, progress: number) => void")),(0,o.yg)("p",null,"A function that gets called with the progress of the rendering process, can be\nused to report progress back to users (e.g. in a web app). The function gets\ncalled with two arguments: the id of the worker that is calling the function,\nand the progress of the rendering process (float between 0 and 1). Does nothing\nby default"),(0,o.yg)("h2",{id:"return-value"},"Return Value"),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"{ audioFile: string, videoFile: string }")),(0,o.yg)("p",null,"Paths to the audio and video files of the partial render."))}u.isMDXComponent=!0}}]);